# API de Voz a Texto (STT) y Texto a Voz (TTS) de Alto Rendimiento

Este proyecto implementa una API RESTful de alta velocidad utilizando FastAPI para realizar dos tareas principales:
1.  **Texto a Voz (TTS)**: Convierte un texto en un archivo de audio y devuelve la URL pÃºblica de S3.
2.  **Voz a Texto (STT)**: Transcribe un archivo de audio corto a texto.

La arquitectura estÃ¡ optimizada para inferencia rÃ¡pida, ideal para audios de 3 a 10 segundos, con un mÃ¡ximo de un minuto.

## ğŸš€ Stack TecnolÃ³gico

| Tarea                 | LibrerÃ­a/MÃ³dulo        | Modelo Recomendado        | RazÃ³n Principal                                                                                             |
| --------------------- | ---------------------- | ------------------------- | ----------------------------------------------------------------------------------------------------------- |
| **Framework API**     | `FastAPI`              | N/A                       | MÃ¡ximo rendimiento y soporte nativo para `async/await`.                                                     |
| **Servidor ASGI**     | `Uvicorn`              | N/A                       | Servidor ASGI ultrarrÃ¡pido para FastAPI.                                                                    |
| **Voz a Texto (STT)** | `faster-whisper`       | `base` o `small`          | La implementaciÃ³n de Whisper mÃ¡s rÃ¡pida. Ofrece gran precisiÃ³n con latencia muy baja para audios cortos.      |
| **Texto a Voz (TTS)** | `Coqui TTS` (`TTS`)    | `tts_models/en/ljspeech/tacotron2-DDC` | Mejor equilibrio entre calidad y velocidad. Ideal para inferencia rÃ¡pida en CPU/GPU.                  |
| **Almacenamiento S3** | `aiobotocore`          | N/A                       | Permite interactuar con S3 de forma asÃ­ncrona, crucial para no bloquear la API durante la subida de archivos. |
| **Estructura Datos**  | `Pydantic`             | N/A                       | ValidaciÃ³n de datos de entrada/salida integrada en FastAPI.                                                 |

## ğŸ“‚ Estructura del Proyecto

```
project_root/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py             # Endpoints de la API (FastAPI)
â”‚   â”œâ”€â”€ config.py           # ConfiguraciÃ³n (variables de entorno)
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ s3_handler.py   # GestiÃ³n asÃ­ncrona con S3 (Aiobotocore)
â”‚   â”‚   â””â”€â”€ loader.py       # Carga de modelos STT y TTS al inicio
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ stt.py          # LÃ³gica de transcripciÃ³n (faster-whisper)
â”‚       â””â”€â”€ tts.py          # LÃ³gica de generaciÃ³n de audio (Coqui TTS)
â”œâ”€â”€ requirements.txt      # Dependencias del proyecto
â””â”€â”€ .env.example          # Ejemplo de variables de entorno
```

## âš™ï¸ ConfiguraciÃ³n

1.  **Clonar el repositorio:**
    ```bash
    git clone <url-del-repositorio>
    cd <nombre-del-repositorio>
    ```

2.  **Crear y activar un entorno virtual:**
    ```bash
    python3 -m venv .venv
    source .venv/bin/activate
    ```

3.  **Instalar dependencias:**
    AsegÃºrate de tener `libsndfile1` instalado en sistemas Debian/Ubuntu para procesar audio.
    ```bash
    sudo apt-get update && sudo apt-get install libsndfile1
    pip install -r requirements.txt
    ```

4.  **Configurar variables de entorno:**
    Crea un archivo `.env` a partir de `.env.example` y complÃ©talo con tus credenciales de AWS y configuraciÃ³n de S3.
    ```bash
    cp .env.example .env
    # Edita el archivo .env con tus valores
    ```

## âš¡ï¸ EjecuciÃ³n

Para iniciar el servidor en modo de desarrollo, ejecuta:

```bash
uvicorn app.main:app --reload
```

La API estarÃ¡ disponible en `http://127.0.0.1:8000`. Puedes acceder a la documentaciÃ³n interactiva de Swagger en `http://127.0.0.1:8000/docs`.

## ğŸ“¦ Despliegue en ProducciÃ³n

Para producciÃ³n, se recomienda usar `gunicorn` como gestor de procesos para los workers de `uvicorn`. Esto proporciona concurrencia y robustez.

```bash
gunicorn -w 4 -k uvicorn.workers.UvicornWorker app.main:app
```

*   `-w 4`: Inicia 4 procesos "worker". El nÃºmero ideal es `(2 * nÃºmero_de_cores_cpu) + 1`.
*   `-k uvicorn.workers.UvicornWorker`: Especifica que `uvicorn` manejarÃ¡ las peticiones dentro de cada worker de `gunicorn`.

**RecomendaciÃ³n de Entorno:** Para la mÃ¡xima velocidad, despliega en una mÃ¡quina virtual o contenedor Docker con una **GPU** y las librerÃ­as CUDA/cuDNN instaladas. La inferencia en GPU es significativamente mÃ¡s rÃ¡pida, especialmente para TTS.