# API de Voz a Texto (STT) y Texto a Voz (TTS) de Alto Rendimiento
 
Este proyecto implementa una API RESTful de alta velocidad utilizando FastAPI para realizar dos tareas principales:
1.  **Voz a Texto (STT)**: Transcribe un archivo de audio a texto utilizando `faster-whisper` para una inferencia ultrarr√°pida.
2.  **Texto a Voz (TTS)**: Convierte un texto en **ingl√©s o espa√±ol** a un archivo de audio `.wav` utilizando `Coqui TTS`, lo sube a un bucket de S3 y devuelve una **URL prefirmada** segura y temporal para su acceso.
 
La arquitectura est√° dise√±ada para ser as√≠ncrona y de alto rendimiento, con soporte para aceleraci√≥n por GPU.

## ‚ú® Caracter√≠sticas Principales

- **As√≠ncrono de Extremo a Extremo**: Construido con FastAPI y `aiobotocore` para un manejo no bloqueante de las peticiones y subidas de archivos.
- **Inferencia R√°pida**: Utiliza `faster-whisper`, una reimplementaci√≥n optimizada de Whisper para transcripciones hasta 4 veces m√°s r√°pidas.
- **TTS Biling√ºe (EN/ES)**: Soporta la generaci√≥n de voz en ingl√©s y espa√±ol utilizando modelos `Tacotron2-DDC` de alta calidad.
- **Seguridad**: Los archivos de audio generados se exponen a trav√©s de URLs prefirmadas de S3 con tiempo de expiraci√≥n, en lugar de URLs p√∫blicas.
- **Protecci√≥n de Endpoints**: Uso de claves de API (`API Key`) para asegurar el acceso a los endpoints y prevenir el uso no autorizado.
- **Optimizaci√≥n de Recursos**: Carga los modelos de IA en memoria una sola vez al inicio de la aplicaci√≥n para minimizar la latencia en las peticiones.
- **Soporte para GPU**: Detecta y utiliza autom√°ticamente una GPU (CUDA) si est√° disponible, para una aceleraci√≥n masiva de la inferencia.
 
## üöÄ Stack Tecnol√≥gico
 
| Tarea                 | Librer√≠a/M√≥dulo        | Modelo Recomendado        | Raz√≥n Principal                                                                                             |
| --------------------- | ---------------------- | ------------------------- | ----------------------------------------------------------------------------------------------------------- |
| **Framework API**     | `FastAPI`              | N/A                       | M√°ximo rendimiento y soporte nativo para `async/await`.                                                     |
| **Servidor ASGI**     | `Uvicorn` / `Gunicorn` | N/A                       | Servidor ASGI ultrarr√°pido, gestionado por Gunicorn en producci√≥n para robustez.                            |
| **Voz a Texto (STT)** | `faster-whisper`       | `base` o `small`          | La implementaci√≥n de Whisper m√°s r√°pida. Ofrece gran precisi√≥n con latencia muy baja para audios cortos.      |
| **Texto a Voz (TTS)** | `Coqui TTS` (`TTS`)    | `tts_models/en/ljspeech/tacotron2-DDC` (EN) y `tts_models/es/mai/tacotron2-DDC` (ES) | Modelos de alta calidad con una arquitectura consistente para ambos idiomas.                                 |
| **Almacenamiento S3** | `aiobotocore`          | N/A                       | Permite interactuar con S3 de forma as√≠ncrona, crucial para no bloquear la API durante la subida de archivos. |
| **Estructura Datos**  | `Pydantic`             | N/A                       | Validaci√≥n de datos de entrada/salida integrada en FastAPI.                                                 |
| **Seguridad API**     | `FastAPI.Security`     | N/A                       | Implementaci√≥n sencilla y est√°ndar de autenticaci√≥n por clave de API en el header.                          |
 
## üìÇ Estructura del Proyecto
 
```
project_root/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ main.py             # Endpoints de la API (FastAPI)
‚îÇ   ‚îú‚îÄ‚îÄ config.py           # Configuraci√≥n (variables de entorno)
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ s3_handler.py   # Gesti√≥n as√≠ncrona con S3 (Aiobotocore)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ loader.py       # Carga de modelos STT y TTS al inicio
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ security.py     # L√≥gica de autenticaci√≥n (API Key)
‚îÇ   ‚îî‚îÄ‚îÄ services/
‚îÇ       ‚îú‚îÄ‚îÄ stt.py          # L√≥gica de transcripci√≥n (faster-whisper)
‚îÇ       ‚îî‚îÄ‚îÄ tts.py          # L√≥gica de generaci√≥n de audio (Coqui TTS)
‚îú‚îÄ‚îÄ requirements.txt      # Dependencias del proyecto
‚îî‚îÄ‚îÄ .env.example          # Ejemplo de variables de entorno
```

## ‚öôÔ∏è Configuraci√≥n

1.  **Clonar el repositorio:**
    ```bash
    git clone <url-del-repositorio> && cd SpeechToText-service
    ```

2.  **Instalar dependencias del sistema:**
    Los modelos TTS requieren `espeak-ng` para la fonetizaci√≥n del texto. `libsndfile1` es necesaria para el procesamiento de audio.
    ```bash
    sudo apt-get update && sudo apt-get install -y espeak-ng libsndfile1
    ```

3.  **Crear y activar un entorno virtual de Python:**
    Se recomienda usar Python 3.11 o superior.
    ```bash
    python3.11 -m venv .venv
    source .venv/bin/activate
    ```

4.  **Instalar dependencias de Python:**
    ```bash
    pip install -r requirements.txt
    ```

5.  **Configurar variables de entorno:**
    Crea un archivo `.env` a partir de `.env.example` y compl√©talo con tus credenciales de AWS y configuraci√≥n de S3.
    ```bash
    cp .env.example .env
    # Edita el archivo .env con tus valores
    ```

## ‚ö°Ô∏è Ejecuci√≥n

Para iniciar el servidor en modo de desarrollo, ejecuta:

```bash
uvicorn src.main:app --reload
```

La API estar√° disponible en `http://127.0.0.1:8000`. Puedes acceder a la documentaci√≥n interactiva de Swagger en `http://127.0.0.1:8000/docs`.

## üì¶ Despliegue en Producci√≥n

Para producci√≥n, se recomienda usar `gunicorn` como gestor de procesos para los workers de `uvicorn`. Esto proporciona concurrencia y robustez.

```bash
gunicorn -w 4 -k uvicorn.workers.UvicornWorker src.main:app
```

*   `-w 4`: Inicia 4 procesos "worker". El n√∫mero ideal es `(2 * n√∫mero_de_cores_cpu) + 1`.
*   `-k uvicorn.workers.UvicornWorker`: Especifica que `uvicorn` manejar√° las peticiones dentro de cada worker de `gunicorn`.

**Recomendaci√≥n de Entorno:** Para la m√°xima velocidad, despliega en una m√°quina virtual o contenedor Docker con una **GPU** y las librer√≠as CUDA/cuDNN instaladas. La inferencia en GPU es significativamente m√°s r√°pida, especialmente para TTS.


## ‚öôÔ∏è Configuraci√≥n Local (Python)

1.  **Clonar el repositorio:**
    ```bash
    git clone <url-del-repositorio> && cd SpeechToText-service
    ```

2.  **Instalar dependencias del sistema:**
    ```bash
    sudo apt-get update && sudo apt-get install -y espeak-ng libsndfile1
    ```

3.  **Configurar entorno:**
    ```bash
    python3.11 -m venv .venv
    source .venv/bin/activate
    pip install -r requirements.txt
    cp .env.example .env
    # Edita el .env con los valores de la tabla de Variables de Entorno
    ```

4.  **Ejecutar:**
    ```bash
    uvicorn src.main:app --reload
    ```

## üê≥ Ejecuci√≥n con Docker (Recomendado)

1.  Aseg√∫rate de tener el archivo `.env` configurado.
2.  Levanta el servicio:
    ```bash
    docker-compose up -d --build
    ```

    *Nota: Docker gestionar√° autom√°ticamente los vol√∫menes para cachear los modelos de IA, evitando descargas repetidas.*

## ‚òÅÔ∏è CI/CD y Despliegue en AWS Lightsail

El proyecto cuenta con pipelines de **GitHub Actions** configurados para desplegar autom√°ticamente en una instancia de **AWS Lightsail (VM)** mediante SSH y Docker Compose.

### Estrategia de Ramas y Ambientes

| Rama | Ambiente | Puerto | Modelo STT | Prefijo S3 |
| :--- | :--- | :--- | :--- | :--- |
| `develop` | Desarrollo | `8001` | `base` | `dev/` |
| `quality` | Calidad (QA) | `8002` | `base` | `qa/` |
| `main` | Producci√≥n | `8000` | `medium` | `prod/` |

### üîê Secretos de GitHub Requeridos

Para que los flujos de trabajo funcionen correctamente, debes configurar los siguientes secretos en tu repositorio (Settings > Secrets and variables > Actions):

#### Credenciales de Conexi√≥n (SSH)
*   `LIGHTSAIL_HOST`: Direcci√≥n IP p√∫blica de tu instancia Lightsail.
*   `LIGHTSAIL_USERNAME`: Usuario SSH (ej: `ubuntu` o `bitnami`).
*   `LIGHTSAIL_SSH_KEY`: Clave privada SSH (.pem) para acceder a la instancia.

#### Variables de Entorno de la Aplicaci√≥n
Estas se inyectan en el contenedor durante el despliegue:
*   `API_KEY`: Clave para proteger los endpoints.
*   `APP_AWS_ACCESS_KEY_ID`: Credenciales para que la app acceda a S3.
*   `APP_AWS_SECRET_ACCESS_KEY`: Credenciales para que la app acceda a S3.
*   `AWS_REGION`: Regi√≥n de AWS para S3.

üì¶ Producci√≥n

Para despliegues manuales en producci√≥n, se recomienda el uso de gunicorn para gestionar los workers de uvicorn:
Bash

gunicorn -w 4 -k uvicorn.workers.UvicornWorker src.main:app

    Consejo de Rendimiento: Para obtener la m√°xima velocidad, despliega en una instancia con GPU NVIDIA y aseg√∫rate de que los drivers CUDA est√©n instalados. La inferencia en GPU reduce dr√°sticamente los tiempos de procesamiento de TTS.